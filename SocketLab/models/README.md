# Models

请下载任一最新的 llama.cpp 支持的模型文件并放置在 `models` 目录下，我们使用的是 [qwen2.5-coder-1.5b-instruct-q8_0.gguf](https://huggingface.co/Qwen/Qwen2.5-Coder-1.5B-Instruct-GGUF/blob/main/qwen2.5-coder-1.5b-instruct-q8_0.gguf)。你可以选择和我们一样的模型文件，但是为了展现这个 lab 的灵活性，你可以尝试不同的模型文件并观察不同的效果。

注意：无论你使用哪个模型文件，请将其重命名为 `model.gguf`，以便于代码的调用。
